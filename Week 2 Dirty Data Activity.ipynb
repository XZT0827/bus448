{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ec3b5f1-7023-485d-a622-c672d157902f",
   "metadata": {},
   "source": [
    "# Dirty Data Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb77cd1-ae69-4d87-b6e4-04f0002d7f0c",
   "metadata": {},
   "source": [
    "If you've download the Week 2 penn_health_records.csv in the same directory as this file you can now move forward with the Dirty Data Activity. This activity has three parts.  First, we will assess. You can run the next block of code.  Review all the comments, commands and output.  Second, we will think critically and reflect. You'll find a series of questions posed. Write answers as comments. Third, we will proceed with cleaning. Run the final code block and again, review the comments, commands and output.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199a416-010f-4b3d-bd2b-d3dbd2ab44cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('Week 2 penn_health_records.csv')\n",
    "\n",
    "# Step 2: Review the Dataset\n",
    "# Display the first few rows of the dataset\n",
    "data.head()\n",
    "\n",
    "# Step 3: Identify Data Issues\n",
    "# 3.1: Check for missing data (NaNs)\n",
    "missing_data = data.isnull().sum()\n",
    "print(\"Missing Data:\\n\", missing_data)\n",
    "\n",
    "# 3.2: Check for inconsistent data formats\n",
    "# Convert 'DateOfVisit' to datetime\n",
    "data['DateOfVisit'] = pd.to_datetime(data['DateOfVisit'], errors='coerce')\n",
    "\n",
    "# Check for invalid dates\n",
    "invalid_dates = data['DateOfVisit'].isnull().sum()\n",
    "print(\"Invalid Dates:\\n\", invalid_dates)\n",
    "\n",
    "# 3.3: Check for duplicate rows\n",
    "duplicates = data.duplicated().sum()\n",
    "print(\"Duplicate Rows:\\n\", duplicates)\n",
    "\n",
    "# 3.4: Check for outliers (e.g., Age, Height, Weight)\n",
    "outliers_age = data[(data['Age'] < 0) | (data['Age'] > 100)]\n",
    "outliers_height = data[(data['Height'] < 140) | (data['Height'] > 200)]\n",
    "outliers_weight = data[(data['Weight'] < 50) | (data['Weight'] > 120)]\n",
    "print(\"Outliers in Age:\\n\", outliers_age)\n",
    "print(\"Outliers in Height:\\n\", outliers_height)\n",
    "print(\"Outliers in Weight:\\n\", outliers_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e93fa19-160b-4f2e-8370-3f2c2e417fb4",
   "metadata": {},
   "source": [
    "Summarize your findings from above. What appears dirty? Be specfic and document the various cases.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19adb025-6614-434f-aa02-0381f6ff5581",
   "metadata": {},
   "source": [
    "What strategies can be used to handle missing data, and how do these strategies impact the overall analysis of the dataset? \n",
    "Provide examples from the Age, Gender, and Height columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc87b2-8020-4cfe-bbe5-2794c9ce0cd0",
   "metadata": {},
   "source": [
    "Explain the methods you can use to detect outliers in a dataset, particularly in columns like Age, Height, and Weight. How would you decide whether to retain, modify, or remove these outliers, and what justifications can you provide for your decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f5cad-4cfa-45c6-9f9d-100d8ebd939a",
   "metadata": {},
   "source": [
    "Why is it important to validate and ensure consistency in data formats, such as dates? Demonstrate how you can identify and correct inconsistent date formats in the DateOfVisit column, and discuss the potential consequences of not addressing these issues.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddf3ee5-f8b8-4e30-8268-892a27eb45cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirty Data Cleaning\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Week 2 penn_health_records.csv')\n",
    "\n",
    "# 1. Handle Missing Data\n",
    "# Fill missing names with a placeholder\n",
    "data['Name'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Fill missing ages with the median\n",
    "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "\n",
    "# Drop rows where Gender is missing\n",
    "data.dropna(subset=['Gender'], inplace=True)\n",
    "\n",
    "# Fill missing heights with the median\n",
    "data['Height'].fillna(data['Height'].median(), inplace=True)\n",
    "\n",
    "# Fill missing weights with the median\n",
    "data['Weight'].fillna(data['Weight'].median(), inplace=True)\n",
    "\n",
    "# Fill missing blood pressure and cholesterol with the most frequent value (mode)\n",
    "data['BloodPressure'].fillna(data['BloodPressure'].mode()[0], inplace=True)\n",
    "data['Cholesterol'].fillna(data['Cholesterol'].mode()[0], inplace=True)\n",
    "\n",
    "# 2. Correct Invalid Dates\n",
    "# Convert 'DateOfVisit' to datetime and handle errors\n",
    "data['DateOfVisit'] = pd.to_datetime(data['DateOfVisit'], errors='coerce')\n",
    "\n",
    "# Fill invalid dates with the most frequent valid date\n",
    "data['DateOfVisit'].fillna(data['DateOfVisit'].mode()[0], inplace=True)\n",
    "\n",
    "# 3. Remove Duplicate Rows\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# 4. Handle Outliers\n",
    "# Replace outliers in Age, Height, and Weight with the median\n",
    "median_age = data['Age'].median()\n",
    "median_height = data['Height'].median()\n",
    "median_weight = data['Weight'].median()\n",
    "\n",
    "data.loc[(data['Age'] < 0) | (data['Age'] > 100), 'Age'] = median_age\n",
    "data.loc[(data['Height'] < 140) | (data['Height'] > 200), 'Height'] = median_height\n",
    "data.loc[(data['Weight'] < 50) | (data['Weight'] > 120), 'Weight'] = median_weight\n",
    "\n",
    "# Save the cleaned dataset\n",
    "data.to_csv('Week 2 penn_health_records_cleaned.csv', index=False)\n",
    "\n",
    "# Verify the cleaning steps\n",
    "print(\"Cleaned Data Summary:\")\n",
    "print(data.describe())\n",
    "print(data.info())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
